
 <h1 align=center> Natural-Language-Processing
</h1>

 

<div >
<p align="center">
    <img src="https://github.com/mrdesautu/Natural-Language-Processing/blob/main/source/an-introduction-to-natural-language-processing-with-python-for-seos-5f3519eeb8368.png" height="80">
  </p>
</div>



 ## <h1 align=center>**`Contexto y Objetivos:`**</h1>
 **What will you find in this section?**	
 + .
</h1>

**Logistic_Regression**
- [Import Functions and Data](#0)
- [1 - Logistic Regression](#1)
    - [1.1 - Sigmoid](#1-1)
        - [Exercise 1 - sigmoid (UNQ_C1)](#ex-1)
    - [1.2 - Cost function and Gradient](#1-2)
        - [Exercise 2 - gradientDescent (UNQ_C2)](#ex-2)
- [2 - Extracting the Features](#2)
    - [Exercise 3 - extract_features (UNQ_C3)](#ex-3)
- [3 - Training Your Model](#3)
- [4 - Test your Logistic Regression](#4)
    - [Exercise 4 - predict_tweet (UNQ_C4)](#ex-4)
    - [4.1 - Check the Performance using the Test Set](#4-1)
        - [Exercise 5 - test_logistic_regression (UNQ_C5)](#ex-5)
- [5 - Error Analysis](#5)
- [6 - Predict with your own Tweet](#6) 
</h1>

**Naive Bayes**
- [Importing Functions and Data](#0)
- [1 - Process the Data](#1)
    - [1.1 - Implementing your Helper Functions](#1-1)
        - [Exercise 1 - count_tweets (UNQ_C1)](#ex-1)
- [2 - Train your Model using Naive Bayes](#2)
    - [Exercise 2 - train_naive_bayes (UNQ_C2)](#ex-2)
- [3 - Test your Naive Bayes](#3)
    - [Exercise 3 - naive_bayes_predict  (UNQ_C4)](#ex-3)
    - [Exercise 4 - test_naive_bayes (UNQ_C6)](#ex-4)
- [4 - Filter words by Ratio of Positive to Negative Counts](#4)
    - [Exercise 5 - get_ratio (UNQ_C8)](#ex-5)
    - [Exercise 6 - get_words_by_threshold (UNQ_C9)](#ex-6)
- [5 - Error Analysis](#5)
- [6 - Predict with your own Tweet](#6)
</h1>


**Hello Vectors**
- [1 - Predict the Countries from Capitals](#1)
    - [1.1 Importing the Data](#1-1)
    - [1.2 Cosine Similarity](#1-2)
        - [Exercise 1 - cosine_similarity (UNQ_C1)](#ex-1)
    - [1.3 Euclidean Distance](#1-3)
        - [Exercise 2 - euclidean (UNQ_C2)](#ex-2)
    - [1.4 Finding the Country of each Capital](#1-4)
        - [Exercise 3 - get_country (UNQ_C3)](#ex-3)
    - [1.5 Model Accuracy](#1-5)
        - [Exercise 4 - get_accuracy (UNQ_C4)](#ex-4)
- [2 - Plotting the vectors using PCA](#2)
    - [Exercise 5 - compute_pca (UNQ_C5)](#ex-5)
</h1>

**Naive Machine Translation and LSH**
- [1. The Word Embeddings Data for English and French Words](#1)
  - [1.1 Generate Embedding and Transform Matrices](#1-1)
      - [Exercise 1 - get_matrices (UNQ_C1)](#ex-1)
- [2 - Translations](#2)
  - [2.1 - Translation as Linear Transformation of Embeddings](#2-1)
      - [Exercise 2 - compute_loss (UNQ_C3)](#ex-2)  
      - [Exercise 3 - compute_gradient (UNQ_C4)](#ex-3)  
      - [Exercise 4 - align_embeddings (UNQ_C5)](#ex-4)        
  - [2.2 - Testing the Translation](#2-2)
      - [Exercise 5 - nearest_neighbor (UNQ_C8)](#ex-5)
      - [Exercise 6 - test_vocabulary (UNQ_C10)](#ex-6)      
- [3 - LSH and Document Search](#3)
  - [3.1 - Getting the Document Embeddings](#3-1)
      - [Exercise 7 - get_document_embedding (UNQ_C12)](#ex-7)
      - [Exercise 8 - get_document_vecs (UNQ_C14)](#ex-8)      
  - [3.2 - Looking up the Tweets](#3-2)
  - [3.3 - Finding the most Similar Tweets with LSH](#3-3)
  - [3.4 - Getting the Hash Number for a Vector](#3-4)
      - [Exercise 9 - hash_value_of_vector (UNQ_C17)](#ex-9)  
  - [3.5 - Creating a Hash Table](#3-5)
      - [Exercise 10 - make_hash_table (UNQ_C19)](#ex-10)  
  - [3.6 - Creating all Hash Tables](#3-6)
      - [Exercise 11 - approximate_knn (UNQ_C21)](#ex-11)


<div >
<p align="center">
    <img src="https://github.com/mrdesautu/Natural-Language-Processing/blob/main/source/Anotaci%C3%B3n%202023-06-28%20135518.png" height="80">
  </p>
</div>





